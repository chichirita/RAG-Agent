

# AI Manager (Marta)

Этот проект представляет собой интеллектуального чат-бота по имени Марта, реализованного в качестве менеджера компании PolarAgency. Система использует технологию RAG для ответов на вопросы, основываясь на данных из загруженных PDF-документов. Это одна из первых версий проекта, реализована на российской модели Saiga Llama 3

## Основные возможности

* **Контекстный поиск:** Бот ищет информацию в PDF-файлах (инструкции, прайсы, услуги) и отвечает строго по делу.
* **Личность (Persona):** Бот настроен как лаконичный менеджер Марта.
* **Сбор лидов:** Система автоматически запрашивает контактные данные пользователя после определенного количества сообщений.
* **Многопоточность и Streaming:** Ответы в Flask-приложении генерируются в реальном времени (потоковая передача токенов).
* **Многоязычность:** Поддержка русского языка с использованием модели `Saiga Llama 3`.

## Технологический стек

* **Backend:** Flask (Python)
* **LLM:** LangChain / LangChain Ollama
* **Векторная база данных:** FAISS
* **Эмбеддинги:** HuggingFace (`intfloat/multilingual-e5-large`)
* **Локальная модель:** Ollama (Saiga Llama 3 8B)
* **UI:** HTML/Templates + Streamit (для тестов)
* **Логирование:** Loguru

---

## Предварительные требования

1. Установленный [Ollama](https://ollama.com/).
2. Скачанная модель Saiga:
```bash
ollama pull bambucha/saiga-llama3:8b

```


3. Python 3.10 или выше.

## Установка и запуск

1. **Клонируйте репозиторий:**
```bash
git clone https://github.com/ваш-логин/polar-agency-ai.git
cd polar-agency-ai

```


2. **Установите зависимости:**
```bash
pip install -r requirements.txt

```


3. **Подготовьте данные:**
* Создайте папку `pdf/`.
* Поместите туда ваши документы в формате `.pdf`.


4. **Запуск основного веб-приложения:**
```bash
python app.py

```


Приложение будет доступно по адресу `http://127.0.0.1:5000`.
5. **Запуск альтернативного UI (Streamlit):**
```bash
streamlit run st.py

```



---

## Структура проекта

* `app.py` — Основной Flask-сервер с логикой диалога и стримингом.
* `Simple_RAG_PDF.py` — Ядро системы: загрузка PDF, создание векторного индекса FAISS и выполнение поиска релевантных частей документа.
* `st.py` — Интерфейс на Streamlit для быстрой проверки ответов модели.
* `pdf/` — Папка для ваших исходных документов.
* `db/` — Локальное хранилище векторной базы данных.

---

## Настройки промпта

Марта следует строгим правилам:

* Отвечает только по контексту.
* Максимум 3 предложения.
* Если информации нет — отвечает "Не знаю".
* На 3-й вопрос запрашивает Email или Телефон.
